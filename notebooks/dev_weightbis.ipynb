{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import networkx as nx\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "file_path = \"../data/1eb80fb8b50.json\"  # Path to the JSON file\n",
    "segment_key = [\"kws-l\", \"loc-l\", \"org-l\", \"per-l\", \"content-segmented\"]  # Keys to extract from JSON\n",
    "Years = [\"2024\"]  # Years to process\n",
    "save_graph = True  # Whether to save the graph\n",
    "name_graph_saved = \"typed_graph\"  # Name of the saved graph file\n",
    "\n",
    "# Load the JSON data\n",
    "try:\n",
    "    with open(file_path, \"r\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {file_path}\")\n",
    "    data = {}\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON decoding error: {e}\")\n",
    "    data = {}\n",
    "\n",
    "# Initialize a list to store extracted data\n",
    "df_kws_article = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for each article\n",
    "for year in Years:\n",
    "    for month in range(1, 13):\n",
    "        for day in range(1, 32):\n",
    "            try:\n",
    "                daily_data = data['data'][str(year)][str(month)][str(day)]\n",
    "                for num, data_tmp in enumerate(daily_data):\n",
    "                    # Extract necessary information\n",
    "                    entry = {\n",
    "                        \"loc-l\": data_tmp.get(\"loc-l\", []),\n",
    "                        \"org-l\": data_tmp.get(\"org-l\", []),\n",
    "                        \"per-l\": data_tmp.get(\"per-l\", []),\n",
    "                        \"content-segmented\": data_tmp.get(\"content-segmented\", []),\n",
    "                    }\n",
    "                    df_kws_article.append(entry)\n",
    "            except KeyError:\n",
    "                # Skip if year, month, or day doesn't exist\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {year}-{month}-{day}: {e}\")\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the type of relations between entities\n",
    "def determine_relation_type(entity1, entity2, content_segment):\n",
    "    \"\"\"\n",
    "    Heuristic to type relations between two entities\n",
    "    based on the content segment.\n",
    "    \"\"\"\n",
    "    if \"financial\" in content_segment or \"economic\" in content_segment:\n",
    "        return \"economic\"\n",
    "    elif \"cooperation\" in content_segment or \"diplomatic\" in content_segment:\n",
    "        return \"diplomatic\"\n",
    "    elif \"aid\" in content_segment or \"humanitarian\" in content_segment:\n",
    "        return \"humanitarian\"\n",
    "    else:\n",
    "        return \"undefined\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m relation_type \u001b[38;5;241m=\u001b[39m determine_relation_type(entity1, entity2, segment)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Add edges safely\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_edge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentity1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity2\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     48\u001b[0m     G[entity1][entity2][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Increment weight if edge exists\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hadia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\networkx\\classes\\graph.py:1314\u001b[0m, in \u001b[0;36mGraph.has_edge\u001b[1;34m(self, u, v)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns True if the edge (u, v) is in the graph.\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \n\u001b[0;32m   1280\u001b[0m \u001b[38;5;124;03mThis is the same as `v in G[u]` without KeyError exceptions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Initialiser un graphe vide\n",
    "G = nx.Graph()\n",
    "\n",
    "for row in df_kws_article:\n",
    "    # Ensure row is a dictionary (to avoid KeyError)\n",
    "    if not isinstance(row, dict):\n",
    "        continue\n",
    "\n",
    "    # Extract the content-segmented data\n",
    "    segments = row.get(\"content-segmented\", [])\n",
    "    \n",
    "    # Ensure segments is iterable\n",
    "    if not isinstance(segments, list):\n",
    "        continue\n",
    "    \n",
    "    # Iterate over each segment to build relationships\n",
    "    for segment in segments:\n",
    "        entities = []\n",
    "        \n",
    "        # Extract entities for loc-l, org-l, and per-l\n",
    "        for key in [\"loc-l\", \"org-l\", \"per-l\"]:\n",
    "            if key in row and isinstance(row[key], list):  # Ensure the value is a list\n",
    "                entities.extend(row[key])  # Append entities from the row\n",
    "\n",
    "        # Iterate over pairs of entities to create relationships\n",
    "        for entity1 in entities:\n",
    "            for entity2 in entities:\n",
    "                if entity1 != entity2:\n",
    "                    # Ensure entities are hashable types\n",
    "                    entity1 = tuple(entity1) if isinstance(entity1, list) else entity1\n",
    "                    entity2 = tuple(entity2) if isinstance(entity2, list) else entity2\n",
    "\n",
    "                    # Skip if entities are still not hashable\n",
    "                    if not isinstance(entity1, (str, int, float, tuple)):\n",
    "                        print(f\"Skipping entity1: {entity1} (type: {type(entity1)})\")\n",
    "                        continue\n",
    "                    if not isinstance(entity2, (str, int, float, tuple)):\n",
    "                        print(f\"Skipping entity2: {entity2} (type: {type(entity2)})\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Determine the relation type\n",
    "                    relation_type = determine_relation_type(entity1, entity2, segment)\n",
    "\n",
    "                    # Add edges safely\n",
    "                    if G.has_edge(entity1, entity2):\n",
    "                        G[entity1][entity2][\"weight\"] += 1  # Increment weight if edge exists\n",
    "                    else:\n",
    "                        G.add_edge(entity1, entity2, weight=1, relation_type=relation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_kws_article))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'entities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntities:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mentities\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'entities' is not defined"
     ]
    }
   ],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
